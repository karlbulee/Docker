{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b411efe",
   "metadata": {},
   "source": [
    "# 자연어 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4acc3e",
   "metadata": {},
   "source": [
    "## 딥러닝 기반 자연어 처리 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c219b",
   "metadata": {},
   "source": [
    "**자연어 처리 모델**\n",
    "- 자연어를 입력 받아서 해당 입력이 특정 범주일 확률을 반환하는 확률 함수\n",
    "\n",
    "**딥러닝 기반 자연어 처리 모델**\n",
    "- BERT, GPT\n",
    "\n",
    "**자연어 처리 모델 과제**\n",
    "- 문서 분류\n",
    "- 문장 쌍 분류\n",
    "- 개체명 인식\n",
    "- 질의응답\n",
    "- 문장 생성\n",
    "\n",
    "**학습**\n",
    "- 출력이 정답에 가까워지도록 모델을 업데이트 하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a209719",
   "metadata": {},
   "source": [
    "## 트랜스퍼 러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eec0a05",
   "metadata": {},
   "source": [
    "**트랜스퍼 러닝**\n",
    "- 특정 태스크를 학습한 모델을 다른 태스크 수행에 재사용하는 기법\n",
    "- 기존보다 모델의 학습 속도 빠르고 새로운 태스크 더 잘 수행하는 경향 있음\n",
    "\n",
    "**업스트림 태스크**\n",
    "- 다음 단어 맞히기, 빈칸 채우기 등 대규모 말뭉치의 문맥을 이해하는 과제\n",
    "- 업스트림 태스크를 학습하는 과정을 프리트레인이라 함 \n",
    "\n",
    "1. 다음 단어 맞히기 \n",
    "- GPT 계열 모델(Ex. 티끌 모아 00) \n",
    "- 언어 모델 \n",
    "- 분류 범주 수 학습 대상 언어의 어휘 수만큼 늘어남. \n",
    "\n",
    "2. 빈칸 채우기 \n",
    "- BERT 계열 모델(Ex. 티클 00 태산)\n",
    "- 앞뒤 문맥을 보고 빈칸에 적합한 단어 알 수 있음 \n",
    "- 마스크 언어 모델 \n",
    "\n",
    "3. 자기지도 학습\n",
    "- 데이터 내에서 정답을 만들고 이를 바탕으로 모델을 학습하는 방법\n",
    "\n",
    "**다운스트림 태스크**\n",
    "- 문서 분류, 개체명 인식 등 풀고자 하는 자연어 처리의 구체적 문제\n",
    "- 프리트레인을 마친 모델을 구조 변경 없이 그대로 사용하거나 태스크 모듈을 덧붙인 형태로 수행\n",
    "\n",
    "**파인튜닝**\n",
    "- 프리트레인을 마친 모델을 다운스트림 태스크에 맞게 업데이트하는 기법\n",
    "\n",
    "1. 문서 분류\n",
    "- 자연어를 입력받아 해당 입력이 어떤 범주에 속하는지 확률값 반환\n",
    "\n",
    "2. 자연어 추론\n",
    "- 문장 2개를 입력받아 두 문장 사이의 관계가 어떤 범주인지 확률값 반환\n",
    "\n",
    "3. 개체명 인식\n",
    "- 자연어를 입력받아 단어별로 어떤 개체명 범주에 속하는지 확률값 반환\n",
    "\n",
    "4. 질의응답\n",
    "- 자연어를 입력받아 각 단어가 정답의 시작일 확률값과 끝일 확률값을 반환\n",
    "\n",
    "5. 문장생성\n",
    "- GPT 계열 언어 몯레이 널리 쓰임\n",
    "- 자연어를 입력받아 어휘 전체에 대한 확률값 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c802124",
   "metadata": {},
   "source": [
    "## 학습 파이프라인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6972e9",
   "metadata": {},
   "source": [
    "- 과제에 상관없이 공통으로 적용\n",
    "1. 각종 설정값 정하기\n",
    "2. 데이터 내려받기\n",
    "3. 프리트레인을 마친 모델 준비하기\n",
    "4. 토크나이저 준비하기\n",
    "5. 데이터 로더 준비하기\n",
    "6. 태스크 정의하기\n",
    "7. 모델 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a732f9ac",
   "metadata": {},
   "source": [
    "### 1. 각종 설정값 정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d61f17",
   "metadata": {},
   "source": [
    "- 어떤 프리트레인 모델을 사용할지\n",
    "- 학습에 사용할 데이터는 무엇인지\n",
    "- 학습 결과는 어디에 저장할지\n",
    "- 하이퍼파라미터(러닝 레이트, 배치 크기 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85365240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T05:56:20.748382Z",
     "start_time": "2022-08-16T05:56:20.381865Z"
    }
   },
   "outputs": [],
   "source": [
    "from ratsnlp.nlpbook.classification import ClassificationTrainArguments\n",
    "args = nlpbook.TrainArguments(\n",
    "    pretrained_model_name=\"beomi/kcbert-base\",\n",
    "    downstream_corpus_name=\"nsmc\",\n",
    "    downstream_corpus_root_dir=\"/content/Korpora\", # colab\n",
    "    downstream_model_dir=\"/gdrive/My Drive/nlpbook/checkpoint-cls\",\n",
    "    learning_rate=5e-5,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e595841",
   "metadata": {},
   "source": [
    "### 2. 데이터 내려받기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3074affd",
   "metadata": {},
   "source": [
    "- 다운스트림 데이터로 사용\n",
    "- NSMC : 네이버 영화 리뷰 말뭉치 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17c7f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Korpora import Korpora # 다양한 한국어 말뭉치 쉽게 내려박고 전처리할 수 있는 패키지\n",
    "Korpora.fetch(\n",
    "    corpus_name=args.downstream_corpus_name, # 말뭉치 다운\n",
    "    root_dir=args.downstream_corpus_root_dir, # 말뭉치 저장\n",
    "    force_download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a883ffb",
   "metadata": {},
   "source": [
    "### 3. 프리트레인을 마친 모델 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb34c50",
   "metadata": {},
   "source": [
    "- 허깅페이스에서 만든 트랜스포머 패키지 사용\n",
    "- 단 몇 줄만으로 모델 사용 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4305068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertForSequenceClassification\n",
    "pretrained_model_config = BertConfig.from_pretrained(\n",
    "    args.pretrained_model_name,\n",
    "    num_labels=2,\n",
    ")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "        args.pretrained_model_name,\n",
    "        config=pretrained_model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccde159",
   "metadata": {},
   "source": [
    "### 4. 토크나이저 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d06e664",
   "metadata": {},
   "source": [
    "- 토큰 : 자연어 처리 모델의 입력. 문장보다 작은 단위\n",
    "- 한 문장은 여러 개의 토큰으로 구성되며 분리 기준은 그때그때 다를 수 있음 \n",
    "- 띄어쓰기로만 나눌 수도 있고, 의미의 최소 단위인 형태소 단위로 나눌 수도 있음 \n",
    "- 토큰화 : 문장을 토큰 시퀀스로 분석하는 과정\n",
    "- 토크나이저 : 토큰화를 수행하는 프로그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53749434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    args.pretrained_model_name,\n",
    "    do_lower_case=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca9c6cd",
   "metadata": {},
   "source": [
    "### 5. 데이터 로더 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f95ff",
   "metadata": {},
   "source": [
    "- 파이토치에는 데이터 로더가 포함됨(반드시 정의)\n",
    "- 데이터 로더는 데이터를 배치 단위로 모델에 밀어 넣어주는 역할 함\n",
    "- 전체 데이터 가운데 일부 인스턴스를 뽑아 배치 구성\n",
    "- 데이터셋은 데이터 로더의 구성 요소 가운데 하나 \n",
    "- 데이터셋은 여러 인스턴스(문서 + 레이블)를 보유\n",
    "- 데이터 로더가 배치를 만들 때 인스턴스를 뽑는 방식은 파이토치 사용자가 자유롭게 정할 수 있음 \n",
    "- 동일한 배치에 있는 문장들의 토큰 개수는 같아야 함\n",
    "\n",
    "**컬레이트** \n",
    "- 배치의 모양 등을 정비해 모델의 최종 입력으로 만들어 주는 과정\n",
    "- 파이썬 리스트에서 파이토치 텐서로의 변환 등 자료형 변환도 포함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdefe6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from ratsnlp.nlpbook.classification import NsmcCorpus, ClassificationDataset corpus = NsmcCorpus()\n",
    "train_dataset = ClassificationDataset(\n",
    "    args=args, \n",
    "    corpus=corpus, \n",
    "    tokenizer=tokenizer, \n",
    "    mode=\"train\",\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size, \n",
    "    sampler=RandomSampler(train_dataset, replacement=False), \n",
    "    collate_fn=nlpbook.data_collator,\n",
    "    drop_last=False,\n",
    "    num_workers=args.cpu_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d720d1cc",
   "metadata": {},
   "source": [
    "### 6. 태스크 정의하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3bbffa",
   "metadata": {},
   "source": [
    "- 파이토치 라이트닝 : 딥러닝 모델을 학습할 때 반복적인 내용을 대신 수행해줘 사용자가 모델 구축에만 신경쓸 수 있도록 돕는 라이브러리\n",
    "- 모델, 최적화 방법, 학습 과정 등이 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b23db28",
   "metadata": {},
   "source": [
    "### 7. 모델 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50af9ce",
   "metadata": {},
   "source": [
    "- Trainer는 파이토치 라이트닝에서 제공하는 객체로 실제 학습 수행\n",
    "- 하드웨어 설정, 학습 기록 로깅, 체크포인트 저장 등 복잡한 설정 알아서 함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae7d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ratsnlp.nlpbook.classification import ClassificationTask\n",
    "task = ClassificationTask(model, args)\n",
    "trainer = nlpbook.get_trainer(args)\n",
    "trainer.fit(\n",
    "    task,\n",
    "    train_dataloader=train_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625dc4f6",
   "metadata": {},
   "source": [
    "## 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d34a01b",
   "metadata": {},
   "source": [
    "**토큰화**\n",
    "- 한 문장을 토큰 시퀀스로 나누는 과정\n",
    "- 수행 대상에 따라 문자, 단어, 서브워드 등 세 가지 방법 존재\n",
    "\n",
    "**토크나이저**\n",
    "- 토큰화를 수행하는 프로그램\n",
    "- 한국어 토크나이저 : 은전한닢(mecab), 꼬꼬마(kkma) 등 \n",
    "\n",
    "**단어(어절) 단위 토큰화 수행**\n",
    "- 공백 분리 : 별도로 토크나이저 쓰지 않아도 됨. 어휘 집합의 크기가 매우 커짐\n",
    "- 학습된 토크나이저 : 어휘 집합 크기 커지는 것 조금 완화\n",
    "- 어휘 집합의 크기가 커지면 모델 학습 어려워 짐\n",
    "\n",
    "**문자 단위 토큰화**\n",
    "- 한글로 표현할 수 있는 글자는 모두 1만 1,172개로 알파벳, 숫자, 기호 등을 고려해도 1만 5000개 넘기 어려움\n",
    "- 미등록 토큰 문제로부터 자유로움\n",
    "- 의미있는 단위가 되기 어려움\n",
    "- 토큰 시퀀스의 길이가 상대적으로 길어짐(학습 어려워져 성능 저하)\n",
    "\n",
    "**서브워드 단위 토큰화**\n",
    "- 단어와 문자 단위 토큰화의 중간에 있는 형태\n",
    "- 어휘 집합 크기가 지나치게 커지지 않으면서도 미등록 토큰 문제를 피하고, 토큰 시퀀스가 너무 길어지지 않게함\n",
    "- 바이트 페어 인코딩"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
