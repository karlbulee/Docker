{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adfe797a",
   "metadata": {},
   "source": [
    "# 트랜스포머"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebfbc72",
   "metadata": {},
   "source": [
    "**트랜스포머**\n",
    "- 2017년에 구글이 제안한 시퀀스-투-시퀀스 모델\n",
    "\n",
    "**시퀀스-투-시퀀스**\n",
    "- 특정 속성을 지닌 시퀀스를 다른 속성의 시퀀스로 변환하는 작업 \n",
    "- 기계번역 예시 : 어떤 언어의 토큰 시퀀스를 다른 언어의 토큰 시퀀스로 변환하는 과제\n",
    "- 소스와 타깃의 길이가 달라도 해당 과제 수행하는 데 문제 없어야 함\n",
    "- 인코더와 디코더 2개 파트로 구성\n",
    "\n",
    "**인코더**\n",
    "- 소스 시퀀스의 정보를 압축해 디코더로 보내는 역할\n",
    "- 인코딩 : 소스 시퀀스 정보를 압축하는 과정 \n",
    "\n",
    "**디코더**\n",
    "- 타깃 시퀀스를 생성하는 과정\n",
    "\n",
    "**트랜스포머의 학습**\n",
    "- 인코더와 디코더 입력이 주어졌을 때 정답에 해당하는 단어의 확률값을 높이는 방식으로 수행 \n",
    "\n",
    "**트랜스포머 블록**\n",
    "- 인코더 블록 : 멀티 헤드 어텐션, 피드포워드 뉴럴 네트워크, 잔차 연결, 레이어 정규화 등 3가지 요소로 구성\n",
    "- 디코더 블록 : 마스크를 적용한 멀티 헤드 어텐션이 인코더 쪽과 다르고, 보내온 정보와 디코더 입력을 함께 이용해 멀티 헤드 어텐션을 수행 \n",
    "\n",
    "**셀프 어텐션**\n",
    "- 어텐션\n",
    "  - 시퀀스 입력에 수행하는 기계학습 방법의 일종\n",
    "  - 시퀀스 요소 가운데 중요한 요소에 집중하고 그렇지 않은 요소는 무시해 태스크 수행 성능 끌어 올림 \n",
    "  - 디코딩할 때 소스 시퀀스 가운데 중요한 요소만 추림\n",
    "  - 소스 시퀀스 전체 단어들과 타깃 시퀀스 단어 하나 사이를 연결\n",
    "  - RNN 구조 위에서 동작\n",
    "  - 타깃 언어의 단어를 1개 생성할 때 1회 수행 \n",
    "  \n",
    "- 셀프 어텐션\n",
    "  - 자신에게 수행하는 어텐션 기법\n",
    "  - 입력 시퀀스 가운데 태스크 수행에 의미 있는 요소들 위주로 정보 추출\n",
    "  - 입력 시퀀스 전체 단어들 사이를 연결 \n",
    "  - RNN 없이 동작 \n",
    "  - 인코더, 디코더 블록의 개수만큼 반복 수행\n",
    "  \n",
    "**합성곱 신경망과 비교**\n",
    "- 합성곱 필터가 단어를 하나씩 넘기면서 차례대로 읽어 들임\n",
    "- 합성곱 필터 크기를 넘어서는 문맥은 읽어내기 어려움 \n",
    "\n",
    "**순한 신경망과 비교**\n",
    "- 시퀀스 정보를 압축하는 데 강점이 있는 구조\n",
    "- 시퀀스 길이가 길어질수록 정보 압축에 문제 발생 \n",
    "\n",
    "**어텐션과 비교**\n",
    "- 디코더가 타깃 시퀀스를 생성할 때 소스 시퀀스 전체에서 어떤 요소에 주목해야 할지 알려줌 \n",
    "- 소스 시퀀스의 길이가 길어지더라도 번역 품질이 떨어지는 것 막을 수 있음 \n",
    "\n",
    "**셀프 어텐션 수행 대상**\n",
    "- 입력 시퀀스 전체 \n",
    "- 문맥 전체를 고려. 모든 경우의 수 고려 \n",
    "\n",
    "**셀프 어텐션 계산**\n",
    "- 쿼리, 키, 밸류가 서로 영향을 주고 받으면서 문장의 의미 계산 \n",
    "\n",
    "**셀프 어텐션 동작 원리**\n",
    "- 입력층 : 모델의 입력을 만드는 계층 \n",
    "- 인코더 입력은 소스 시퀀스의 입력 임베딩에 위치 정보를 더해서 만듦. 소스 언어 문장의 토큰 인덱스 시퀀스\n",
    "- 출력층의 입력은 디코더 마지막 블록의 출력 벡터 시퀀스 \n",
    "\n",
    "**셀프 어텐션 내부 동작**\n",
    "- 쿼리, 키, 밸류 만들기 \n",
    "- 첫 번째 쿼리의 셀프 어텐션 출력값 계산 \n",
    "- 두 번째 쿼리의 셀프 어텐션 출력값 계산\n",
    "- 세 번째 쿼리의 셀프 어텐션 출력값 계산\n",
    "\n",
    "**멀티 헤드 어텐션**\n",
    "- 셀프 어텐션을 동시에 여러 번 수행 \n",
    "- 여러 헤드가 독자적으로 셀프 어텐션 계산 \n",
    "- 최종 수행 결과 : 입력 단어 수 X 목표 차원 수 \n",
    "- 특별한 언급이 없다면 셀프 어텐션은 멀티 헤드 어텐션 \n",
    "\n",
    "**인코더에서 수행하는 셀프 어텐션**\n",
    "- 쿼리, 키, 밸류가 모두 소스 시퀀스와 관련된 정보\n",
    "- 소스 시퀀스 내의 모든 단어 쌍 사이의 관계 고려\n",
    "\n",
    "**디코더에서 수행하는 셀프 어텐션**\n",
    "- 마스크 멀티 헤드 어텐션 : 타깃 언어의 단어 벡터 시퀀스를 계산 대상으로 함 \n",
    "- 멀티 헤드 어텐션 : 인코더와 디코더 쪽 정보를 모두 활용 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
